{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomNpyDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, num_classes, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.endswith('.npy')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        \n",
    "        # Load .npy files with allow_pickle=True\n",
    "        image = np.load(os.path.join(self.image_dir, img_name), allow_pickle=True)\n",
    "        label = np.load(os.path.join(self.label_dir, img_name), allow_pickle=True)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # Shape: [C, H, W]\n",
    "        \n",
    "        # Ensure label values are within the valid range\n",
    "        label = torch.tensor(label, dtype=torch.long)  # Shape: [H, W]\n",
    "        label = torch.clamp(label, 0, self.num_classes - 1)  # Clamp label values to [0, num_classes-1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Example of how to use the CustomNpyDataset class\n",
    "image_dir = '/home/yshao/unet/lc/images'\n",
    "label_dir = '/home/yshao/unet/lc/labels'\n",
    "num_classes = 2  # Set the number of classes you have\n",
    "\n",
    "transform = None  # Add any necessary transformations here\n",
    "\n",
    "dataset = CustomNpyDataset(image_dir, label_dir, num_classes, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the device to use (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        \n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        self.decoder4 = self.conv_block(1024 + 512, 512)\n",
    "        self.decoder3 = self.conv_block(512 + 256, 256)\n",
    "        self.decoder2 = self.conv_block(256 + 128, 128)\n",
    "        self.decoder1 = self.conv_block(128 + 64, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.encoder3(F.max_pool2d(enc2, 2))\n",
    "        enc4 = self.encoder4(F.max_pool2d(enc3, 2))\n",
    "        \n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))\n",
    "        \n",
    "        dec4 = self.decoder4(torch.cat([F.interpolate(bottleneck, scale_factor=2, mode='bilinear', align_corners=True), enc4], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([F.interpolate(dec4, scale_factor=2, mode='bilinear', align_corners=True), enc3], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([F.interpolate(dec3, scale_factor=2, mode='bilinear', align_corners=True), enc2], dim=1))\n",
    "        dec1 = self.decoder1(torch.cat([F.interpolate(dec2, scale_factor=2, mode='bilinear', align_corners=True), enc1], dim=1))\n",
    "        \n",
    "        return self.final_conv(dec1)\n",
    "\n",
    "# Initialize the model and move it to the appropriate device\n",
    "model = UNet(in_channels=5, out_channels=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
