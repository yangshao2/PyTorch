{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomTiffDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.endswith('.tif')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        \n",
    "        # Load TIFF files using rasterio\n",
    "        with rasterio.open(os.path.join(self.image_dir, img_name)) as src_image:\n",
    "            image = src_image.read().astype(np.float32)  # Read all bands (assume 4 bands)\n",
    "        \n",
    "        # Construct the corresponding label filename\n",
    "        label_name = img_name.replace('image_patch_', 'label_patch_')\n",
    "        \n",
    "        with rasterio.open(os.path.join(self.label_dir, label_name)) as src_label:\n",
    "            label = src_label.read(1).astype(np.int64)  # Read as single channel, convert to long for class indices\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.tensor(image, dtype=torch.float32)  # Shape: [C, H, W]\n",
    "        \n",
    "        # Ensure label values are within the valid range\n",
    "        label = torch.tensor(label, dtype=torch.int64)  # Shape: [H, W]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Example of how to use the CustomTiffDataset class\n",
    "image_dir = '/home/yshao/unet/lc/newtrain/images'\n",
    "label_dir = '/home/yshao/unet/lc/newtrain/labels'\n",
    "\n",
    "# Define transforms including normalization\n",
    "mean = [0.485, 0.456, 0.406, 0.5,0.5]  # Update mean for 4 bands\n",
    "std = [0.229, 0.224, 0.225, 0.25,0.25]  # Update std for 4 bands\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # Scale the input values to [0, 1] if needed; otherwise, comment out the line below\n",
    "    # transforms.Lambda(lambda x: x / 255.0),  \n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize the tensors\n",
    "])\n",
    "\n",
    "dataset = CustomTiffDataset(image_dir, label_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Example to verify data loading\n",
    "for images, labels in dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        \n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        self.decoder4 = self.conv_block(1024 + 512, 512)\n",
    "        self.decoder3 = self.conv_block(512 + 256, 256)\n",
    "        self.decoder2 = self.conv_block(256 + 128, 128)\n",
    "        self.decoder1 = self.conv_block(128 + 64, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.encoder3(F.max_pool2d(enc2, 2))\n",
    "        enc4 = self.encoder4(F.max_pool2d(enc3, 2))\n",
    "        \n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))\n",
    "        \n",
    "        dec4 = self.decoder4(torch.cat([F.interpolate(bottleneck, scale_factor=2, mode='bilinear', align_corners=True), enc4], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([F.interpolate(dec4, scale_factor=2, mode='bilinear', align_corners=True), enc3], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([F.interpolate(dec3, scale_factor=2, mode='bilinear', align_corners=True), enc2], dim=1))\n",
    "        dec1 = self.decoder1(torch.cat([F.interpolate(dec2, scale_factor=2, mode='bilinear', align_corners=True), enc1], dim=1))\n",
    "        \n",
    "        return self.final_conv(dec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the device to use (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the appropriate device\n",
    "model = UNet(in_channels=5, out_channels=3).to(device)\n",
    "\n",
    "# Define the class weights (example weights, you need to calculate based on your dataset)\n",
    "class_weights = torch.tensor([0.1, 1.0, 1.0], device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Define the optimizer with a lower learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "# Custom loss function to ignore 0s in the labels and apply class weights\n",
    "def masked_weighted_cross_entropy_loss(outputs, labels):\n",
    "    # Flatten the outputs and labels\n",
    "    outputs = outputs.permute(0, 2, 3, 1).contiguous().view(-1, outputs.size(1))\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    # Create a mask to ignore 0s in the labels\n",
    "    mask = labels != 0\n",
    "    \n",
    "    # Apply mask to outputs and labels\n",
    "    outputs = outputs[mask]\n",
    "    labels = labels[mask]\n",
    "    \n",
    "    return F.cross_entropy(outputs, labels, weight=class_weights)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = masked_weighted_cross_entropy_loss(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/home/yshao/unet/lc'\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
    "torch.save(model.state_dict(), checkpoint_path)\n",
    "print(f'Model saved to {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import rasterio\n",
    "\n",
    "def load_image(image_path, transform=None):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read().astype(np.float32)\n",
    "    image = torch.tensor(image, dtype=torch.float32)  # Convert to tensor\n",
    "    if transform:\n",
    "        image = transform(image)\n",
    "    return image\n",
    "\n",
    "def predict_and_save(image_path, model, device, transform=None, output_dir=None):\n",
    "    # Load and preprocess the image\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = load_image(image_path, transform).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        output = model(image)\n",
    "        pred_mask = torch.softmax(output, dim=1).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Get the class with the highest probability for each pixel\n",
    "        pred_mask = np.argmax(pred_mask, axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Load the original image metadata for saving\n",
    "        with rasterio.open(image_path) as src:\n",
    "            meta = src.meta.copy()\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "        \n",
    "        # Update metadata to ensure compatibility with uint8\n",
    "        meta.update({\n",
    "            'count': 1,\n",
    "            'dtype': 'uint8',\n",
    "            'height': pred_mask.shape[0],\n",
    "            'width': pred_mask.shape[1],\n",
    "            'transform': transform,\n",
    "            'crs': crs\n",
    "        })\n",
    "        \n",
    "        # Remove nodata value if it's outside the uint8 range\n",
    "        if 'nodata' in meta and (meta['nodata'] < 0 or meta['nodata'] > 255):\n",
    "            del meta['nodata']\n",
    "        \n",
    "        # Save the predicted mask as a TIFF file\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(output_dir, os.path.basename(image_path).replace('image_', 'predicted_'))\n",
    "            with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "                dst.write(pred_mask, 1)\n",
    "            print(f'Saved predicted mask to {output_path}')\n",
    "\n",
    "# Function to process all TIFF files in a directory\n",
    "def process_folder(input_dir, model, device, transform=None, output_dir=None):\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.tif'):\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            predict_and_save(image_path, model, device, transform, output_dir)\n",
    "\n",
    "# Example usage\n",
    "input_dir = '/home/yshao/unet/lc/newtrain/images'\n",
    "output_dir = '/home/yshao/unet/lc/predictions'  # Directory to save the predicted masks\n",
    "\n",
    "# Define the same transform used for training\n",
    "mean = [0.485, 0.456, 0.406, 0.5,0.5]  # Update mean for 5 bands\n",
    "std = [0.229, 0.224, 0.225, 0.25,0.25]  # Update std for 5 bands\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize the tensors\n",
    "])\n",
    "\n",
    "# Assuming model and device are already defined and model is loaded with weights\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=5, out_channels=3).to(device)  # Adjust output channels for 3 classes\n",
    "model.load_state_dict(torch.load('/home/yshao/unet/lc/model_epoch_50.pth'))\n",
    "\n",
    "# Process all TIFF files in the input directory\n",
    "process_folder(input_dir, model, device, transform=transform, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import glob\n",
    "\n",
    "def mosaic_tifs(input_dir, output_file):\n",
    "    # Get list of all tif files in the directory\n",
    "    search_criteria = \"*.tif\"\n",
    "    q = os.path.join(input_dir, search_criteria)\n",
    "    tif_files = glob.glob(q)\n",
    "    \n",
    "    # List to store opened datasets\n",
    "    src_files_to_mosaic = []\n",
    "    \n",
    "    for fp in tif_files:\n",
    "        src = rasterio.open(fp)\n",
    "        src_files_to_mosaic.append(src)\n",
    "    \n",
    "    # Merge function returns a single array and the transformation info\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "    \n",
    "    # Copy the metadata\n",
    "    out_meta = src.meta.copy()\n",
    "    \n",
    "    # Update the metadata with the new dimensions, transform (affine) and CRS\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_trans,\n",
    "        \"crs\": src.crs\n",
    "    })\n",
    "    \n",
    "    # Write the mosaic raster to disk\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "    \n",
    "    # Close all the opened files\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "    \n",
    "    print(f\"Mosaic saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = '/home/yshao/unet/lc/predictions'\n",
    "output_file = '/home/yshao/unet/lc/mosaic.tif'\n",
    "\n",
    "mosaic_tifs(input_dir, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
